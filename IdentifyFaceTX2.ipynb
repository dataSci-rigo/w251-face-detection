{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mtcnn\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/c7/8546b18fbd367b156c5bbbbaa8912ab31c8129171523ff8b47b546d70b09/mtcnn-0.0.9.tar.gz (2.3MB)\n",
      "\u001b[K    100% |################################| 2.3MB 269kB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: mtcnn\n",
      "  Running setup.py bdist_wheel for mtcnn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/85/81/65/6363fa5aafd7a155c896591e0c7c6e27b69642aa82b9cbf076\n",
      "Successfully built mtcnn\n",
      "Installing collected packages: mtcnn\n",
      "Successfully installed mtcnn-0.0.9\n",
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-m_kdphuj-build\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from keras-vggface==0.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/lib/python3/dist-packages (from keras-vggface==0.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6)\n",
      "Installing collected packages: keras-vggface\n",
      "  Running setup.py install for keras-vggface ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed keras-vggface-0.6\n"
     ]
    }
   ],
   "source": [
    "#!sudo apt-get install python3-opencv\n",
    "\n",
    "!pip3 install mtcnn\n",
    "!pip3 install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import urllib\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.spatial.distance import cosine\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from numpy import asarray\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import send_email_attach_aws_ses as sendemail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "        # load image from file\n",
    "        pixels = pyplot.imread(filename)\n",
    "        # create the detector, using default weights\n",
    "        detector = MTCNN()\n",
    "        # detect faces in the image\n",
    "        results = detector.detect_faces(pixels)\n",
    "        # extract the bounding box from the first face\n",
    "        x1, y1, width, height = results[0]['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # extract the face\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        # resize pixels to the model size\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "        face_array = asarray(image)\n",
    "        return face_array\n",
    "\n",
    "\n",
    "# extract faces and calculate face embeddings for a list of photo files\n",
    "def get_embeddings(filenames):\n",
    "        # extract faces\n",
    "        faces = [extract_face(f) for f in filenames]\n",
    "        # convert into an array of samples\n",
    "        samples = asarray(faces, 'float32')\n",
    "        # prepare the face for the model, e.g. center pixels\n",
    "        samples = preprocess_input(samples, version=2)\n",
    "        # create a vggface model\n",
    "        model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "        # perform prediction\n",
    "        yhat = model.predict(samples)\n",
    "        return yhat\n",
    "\n",
    "# determine if a candidate face is a match for a known face\n",
    "def is_match(known_embedding, candidate_embedding, thresh=0.5):\n",
    "        # calculate distance between embeddings\n",
    "        score = cosine(known_embedding, candidate_embedding)\n",
    "        matched = score <= thresh\n",
    "        \n",
    "        return matched, score, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rishi_img = ['images/rishi.jpeg']\n",
    "rishi_240_img = ['images/rishi-240.jpg']\n",
    "sharon_stone1_img = ['images/sharon_stone1.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mtcnn/layer_factory.py:221: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "rm_embed = get_embeddings(rishi_img)\n",
    "rm_240_embed = get_embeddings(rishi_240_img)\n",
    "ss_embed = get_embeddings(sharon_stone1_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_match(isMatched):\n",
    "    if isMatched[0]:\n",
    "        print('>face is a Match (%.3f <= %.3f)' % (isMatched[1], isMatched[2]))\n",
    "    else:\n",
    "        print('>face is NOT a Match (%.3f > %.3f)' % (isMatched[1], isMatched[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Test\n",
      ">face is a Match (0.077 <= 0.500)\n",
      ">face is a Match (-0.000 <= 0.500)\n",
      "Negative Test\n",
      ">face is NOT a Match (0.801 > 0.500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive Test\")\n",
    "print_match(is_match(rm_embed, rm_240_embed))\n",
    "print_match(is_match(rm_embed, rm_embed))\n",
    "\n",
    "print(\"Negative Test\")\n",
    "print_match(is_match(rm_embed, ss_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resized_img(image):\n",
    "    #plt.imshow(image)\n",
    "    return np.array(image.resize((20, 20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wm_image(cp, index):          \n",
    "    ret, frame = cp.read()\n",
    "    impath = \"images/face\" + str(index) + \".jpg\"    \n",
    "    \n",
    "    #image_resized = get_resized_img(frame) \n",
    "    \n",
    "    cv.imwrite(impath, frame)    \n",
    "    return impath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_camp_and_detect(num_of_samples):\n",
    "    cap = cv.VideoCapture(1)\n",
    "    try:\n",
    "    \n",
    "        count = 0\n",
    "\n",
    "        while(count < num_of_samples):\n",
    "            cur_img_path = get_wm_image(cap, count)\n",
    "            \n",
    "            print(cur_img_path)               \n",
    "                                  \n",
    "            unknown_embed = get_embeddings([cur_img_path])\n",
    "            isMatched = is_match(rm_embed, unknown_embed)\n",
    "            \n",
    "            print_match(isMatched)\n",
    "                        \n",
    "            if isMatched[0] == False:\n",
    "                sendemail.send_email(cur_img_path, \"Security Alert - Door 2\", \"Unidentified Person\")\n",
    "            \n",
    "            os.remove(cur_img_path)\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/face0.jpg\n",
      ">face is a Match (0.440 <= 0.500)\n",
      "Email sent! Message ID:\n",
      "0100016c3964803d-82061fc5-818e-4639-b33e-2af9ed4b8d7a-000000\n",
      "Runtime: 62.817552 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "capture_camp_and_detect(1)\n",
    "\n",
    "t1 = time.time()\n",
    "print('Runtime: %f seconds' % (float(t1 - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
